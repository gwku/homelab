---
- name: Prepare all nodes
  hosts: all
  become: yes
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Update and upgrade apt packages
      apt:
        upgrade: dist
        update_cache: yes
        cache_valid_time: 3600

    - name: Check if swap is enabled
      shell: swapon --show
      register: swap_status
      ignore_errors: yes
      changed_when: false

    - name: Disable swap
      shell: swapoff -a
      when: swap_status.stdout != ""

    - name: Check for uncommented swap entries in fstab
      shell: grep -E '^[^#]*\s+swap\s+' /etc/fstab || echo "no_swap_found"
      register: fstab_swap_check
      changed_when: false

    - name: Comment out swap entries in fstab
      shell: sed -i '/ swap / s/^/#/' /etc/fstab
      when: fstab_swap_check.stdout != "no_swap_found" and fstab_swap_check.stdout != ""

    - name: Comment out update_etc_hosts in cloud.cfg to prevent overwrite
      lineinfile:
        path: /etc/cloud/cloud.cfg
        regexp: '^(\s*)-\s*update_etc_hosts'
        line: '#\1- update_etc_hosts'
        backrefs: yes
      ignore_errors: yes

    - name: Check if overlay module is loaded
      shell: lsmod | grep overlay
      register: overlay_loaded
      ignore_errors: yes
      changed_when: false

    - name: Check if br_netfilter module is loaded
      shell: lsmod | grep br_netfilter
      register: br_netfilter_loaded
      ignore_errors: yes
      changed_when: false

    - name: Load overlay kernel module
      shell: modprobe overlay
      when: overlay_loaded.rc != 0

    - name: Load br_netfilter kernel module
      shell: modprobe br_netfilter
      when: br_netfilter_loaded.rc != 0

    - name: Ensure kernel modules load at boot
      copy:
        dest: /etc/modules-load.d/kubernetes.conf
        content: |
          overlay
          br_netfilter
        mode: '0644'

    - name: Set sysctl params for Kubernetes
      copy:
        dest: /etc/sysctl.d/kubernetes.conf
        content: |
          net.bridge.bridge-nf-call-ip6tables = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
        mode: '0644'
      register: sysctl_config_changed

    - name: Apply sysctl params
      command: sysctl --system
      when: sysctl_config_changed.changed

    - name: Configure /etc/hosts for cluster nodes
      blockinfile:
        path: /etc/hosts
        block: |
          # Kubernetes cluster nodes
          {% for host in groups['masters'] | default([]) %}
          {{ hostvars[host]['ansible_default_ipv4']['address'] }} {{ host }}
          {% endfor %}
          {% for host in groups['workers'] | default([]) %}
          {{ hostvars[host]['ansible_default_ipv4']['address'] }} {{ host }}
          {% endfor %}
        marker: "# {mark} ANSIBLE MANAGED KUBERNETES CLUSTER HOSTS"
        create: yes
        backup: yes

    - name: Install dependencies
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
        state: present
        update_cache: yes

    - name: Get distribution codename
      shell: . /etc/os-release && echo "$VERSION_CODENAME"
      register: distro_codename
      changed_when: false

    - name: Add Docker GPG key
      ansible.builtin.apt_key:
        url: https://download.docker.com/linux/debian/gpg
        state: present

    - name: Add Docker repository
      ansible.builtin.apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/debian {{ distro_codename.stdout }} stable"
        state: present
        filename: docker

    - name: Install containerd
      apt:
        name: containerd.io
        state: present
        update_cache: yes

    - name: Check if containerd is already configured
      stat:
        path: /etc/containerd/config.toml
      register: containerd_config_exists

    - name: Check if CRI plugin is disabled (problematic config)
      shell: grep "disabled_plugins.*cri" /etc/containerd/config.toml
      register: cri_disabled_check
      ignore_errors: yes
      changed_when: false
      when: containerd_config_exists.stat.exists

    - name: Check if containerd SystemdCgroup is enabled
      shell: grep "SystemdCgroup = true" /etc/containerd/config.toml
      register: containerd_systemd_check
      ignore_errors: yes
      changed_when: false
      when: containerd_config_exists.stat.exists

    - name: Create containerd config directory
      file:
        path: /etc/containerd
        state: directory
        mode: '0755'

    - name: Generate proper containerd config
      shell: containerd config default > /etc/containerd/config.toml
      when: not containerd_config_exists.stat.exists or (containerd_config_exists.stat.exists and cri_disabled_check.rc == 0)
      register: containerd_config_generated

    - name: Enable SystemdCgroup in containerd config
      shell: sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
      when: containerd_config_generated.changed or (containerd_config_exists.stat.exists and containerd_systemd_check.rc != 0)
      register: containerd_config_updated

    - name: Restart and enable containerd
      systemd:
        name: containerd
        state: restarted
        enabled: yes
      when: containerd_config_generated.changed or containerd_config_updated.changed

    - name: Check if Kubernetes repository is already configured
      stat:
        path: /etc/apt/sources.list.d/kubernetes.list
      register: k8s_repo_exists

    - name: Check if Kubernetes GPG key exists
      stat:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      register: k8s_gpg_exists

    - name: Create keyrings directory
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'
      when: not k8s_gpg_exists.stat.exists

    - name: Add Kubernetes GPG key
      shell: curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      when: not k8s_gpg_exists.stat.exists

    - name: Set permissions on Kubernetes GPG key
      file:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        mode: '0644'
      when: not k8s_gpg_exists.stat.exists

    - name: Add Kubernetes repository
      copy:
        dest: /etc/apt/sources.list.d/kubernetes.list
        content: 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /'
        mode: '0644'
      when: not k8s_repo_exists.stat.exists

    - name: Install Kubernetes components
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Check if kubelet is held
      ansible.builtin.shell: "apt-mark showhold | grep -w kubelet"
      register: kubelet_held
      ignore_errors: yes

    - name: Hold kubelet, kubeadm, and kubectl packages
      ansible.builtin.command:
        cmd: "apt-mark hold kubelet kubeadm kubectl"
      when: kubelet_held.rc != 0

- name: Initialize primary master node
  hosts: masters[0]
  become: yes
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Initialize Kubernetes master
      shell: |
        kubeadm init \
        --control-plane-endpoint={{ cluster_endpoint }} \
        --pod-network-cidr={{ pod_network_cidr }} \
        --cri-socket=unix:///run/containerd/containerd.sock
      args:
        creates: /etc/kubernetes/admin.conf

    - name: Check if kubeconfig exists for user
      stat:
        path: /home/debian/.kube/config
      register: user_kubeconfig_exists

    - name: Copy kubeconfig to user
      become_user: debian
      shell: |
        mkdir -p $HOME/.kube
        sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
        sudo chown $(id -u):$(id -g) $HOME/.kube/config
      when: not user_kubeconfig_exists.stat.exists

    - name: Check if join command file exists
      stat:
        path: /join-command.sh
      register: join_command_file_exists

    - name: Generate and save join command
      block:
        - name: Save join command
          shell: |
            kubeadm token create --print-join-command --ttl 30m
          register: join_cmd
          changed_when: false

        - name: Save join command to file
          copy:
            dest: /join-command.sh
            content: |
              #!/bin/bash
              {{ join_cmd.stdout }}
            mode: '0755'
      when: not join_command_file_exists.stat.exists

- name: Install Cilium CNI
  hosts: masters[0]
  become_user: debian
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Install CNI plugins
      become: yes
      ansible.builtin.get_url:
        url: https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
        dest: /tmp/cni-plugins.tgz
        mode: '0644'

    - name: Create CNI directory
      become: yes
      file:
        path: /opt/cni/bin
        state: directory
        mode: '0755'

    - name: Extract CNI plugins
      become: yes
      ansible.builtin.unarchive:
        src: /tmp/cni-plugins.tgz
        dest: /opt/cni/bin
        remote_src: yes

    - name: Configure CNI loopback and portmap
      become: yes
      copy:
        dest: /etc/cni/net.d/00-kubernetes.conflist
        content: |
          {
            "name": "k8s-pod-network",
            "cniVersion": "0.4.0",
            "plugins": [
              {
                "type": "loopback"
              },
              {
                "type": "portmap",
                "capabilities": {"portMappings": true},
                "externalSetMarkChain": "KUBE-MARK-MASQ"
              },
              {
                "type": "bandwidth",
                "capabilities": {"bandwidth": true}
              }
            ]
          }
        mode: '0644'

    - name: Download Cilium CLI
      shell: |
        CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
        CLI_ARCH=amd64
        if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
        curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
        sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
        sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
        rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
      args:
        creates: /usr/local/bin/cilium

    - name: Check if Cilium is already installed
      shell: kubectl get pods -n kube-system -l k8s-app=cilium
      environment:
        KUBECONFIG: /home/debian/.kube/config
      register: cilium_check
      ignore_errors: yes
      changed_when: false

    - name: Install Cilium
      shell: cilium install --version 1.17.5
      environment:
        KUBECONFIG: /home/debian/.kube/config
      when: cilium_check.rc != 0

    - name: Wait for Cilium pods to be ready
      shell: kubectl wait --for=condition=Ready pods --all -n kube-system -l k8s-app=cilium --timeout=300s
      environment:
        KUBECONFIG: /home/debian/.kube/config
      retries: 30
      delay: 10
      register: cilium_ready
      until: cilium_ready.rc == 0

    - name: Verify Cilium installation
      shell: cilium status
      environment:
        KUBECONFIG: /home/debian/.kube/config
      register: cilium_status

    - name: Display Cilium status
      debug:
        var: cilium_status.stdout_lines

- name: Install and Bootstrap Flux GitOps
  hosts: masters[0]
  become_user: debian
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Check if flux is already installed
      shell: which flux
      register: flux_check
      ignore_errors: yes
      changed_when: false

    - name: Install Flux CLI
      become: yes
      shell: curl -s https://fluxcd.io/install.sh | bash
      when: flux_check.rc != 0

    - name: Check if personal access token exists
      stat:
        path: /home/debian/.flux-token
      register: token_file_exists

    - name: Ensure GitHub personal access token is set
      fail:
        msg: "Please set github_token in vars.yml or create /home/debian/.flux-token with your GitHub personal access token"
      when: not token_file_exists.stat.exists and github_token is not defined

    - name: Create token file if using vars
      copy:
        content: "{{ github_token }}"
        dest: /home/debian/.flux-token
        mode: '0600'
      when: not token_file_exists.stat.exists and github_token is defined

    - name: Read GitHub token
      slurp:
        src: /home/debian/.flux-token
      register: github_token_file

    - name: Bootstrap Flux with GitHub
      shell: |
        export GITHUB_TOKEN="{{ github_token_file['content'] | b64decode | trim }}"
        flux bootstrap github \
          --owner={{ flux_github_owner }} \
          --repository={{ flux_repository }} \
          --branch={{ flux_branch }} \
          --path={{ flux_path }} \
          --personal \
          --components-extra=image-reflector-controller,image-automation-controller
      environment:
        KUBECONFIG: /home/debian/.kube/config
      register: flux_bootstrap
      changed_when: "'Flux is already installed' not in flux_bootstrap.stderr"

    - name: Verify Flux installation
      shell: flux check
      environment:
        KUBECONFIG: /home/debian/.kube/config
      register: flux_status

    - name: Display Flux status
      debug:
        var: flux_status.stdout_lines

- name: Join additional masters
  hosts: masters[1:]
  become: yes
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Check if node is already part of the cluster
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf_exists

    - name: Join master to cluster as control plane
      block:
        - name: Get fresh certificate key from primary master
          shell: kubeadm init phase upload-certs --upload-certs | tail -1
          register: cert_key
          delegate_to: "{{ primary_master }}"
          become: yes

        - name: Generate control plane join command from primary master
          shell: |
            kubeadm token create --print-join-command --ttl 30m
          register: cp_join_cmd
          delegate_to: "{{ primary_master }}"
          become: yes

        - name: Execute join command
          shell: |
            {{ cp_join_cmd.stdout }} --control-plane --certificate-key {{ cert_key.stdout }}
      when: not kubelet_conf_exists.stat.exists and groups['masters'] | length > 1

    - name: Setup kubeconfig for additional masters
      block:
        - name: Create .kube directory for debian user
          file:
            path: /home/debian/.kube
            state: directory
            owner: debian
            group: debian
            mode: '0755'

        - name: Copy admin.conf to debian user
          copy:
            src: /etc/kubernetes/admin.conf
            dest: /home/debian/.kube/config
            owner: debian
            group: debian
            mode: '0644'
            remote_src: yes
      when: not kubelet_conf_exists.stat.exists and groups['masters'] | length > 1

- name: Join worker nodes
  hosts: workers
  become: yes
  vars_files:
    - vars.yml
    - "{{ lookup('first_found', {'files': ['vars.local.yml'], 'skip': true}) | default('vars.yml') }}"
  tasks:
    - name: Check if worker node is already part of the cluster
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: worker_kubelet_conf_exists

    - name: Read join command from primary master
      slurp:
        src: /join-command.sh
      register: join_command_content
      delegate_to: "{{ primary_master }}"
      when: not worker_kubelet_conf_exists.stat.exists

    - name: Copy join command to worker nodes
      copy:
        dest: /tmp/join-command.sh
        content: "{{ join_command_content.content | b64decode }}"
        mode: '0755'
      when: not worker_kubelet_conf_exists.stat.exists

    - name: Join worker to cluster
      shell: bash /tmp/join-command.sh
      when: not worker_kubelet_conf_exists.stat.exists
